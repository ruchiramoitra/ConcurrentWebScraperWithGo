# ConcurrentWebScraperWithGo

This is an ongoing project. Will update as I proceed.

Purpose

To have more end-to-end concepts of Golang like concurrency, channels, goroutines, testing concurrent code, rate limiting, etc.

What is a web scraper?

Web scraping applications should be able to go through a large number of websites, and fetch information from them. Now the information we get from them is unstructured from HTML and we need to transform it to structured data and save it in a database.

What is concurrent web scraping?

It should be able to extract data from multiple websites in parallel. This will make it faster and more efficient.

Concepts to be covered

- Concurrency 
- Parallelism
- Asynchronous I/O
- HTTP request handling
- Data storage
- Rate Limiting
- Data processing and Transformation
- Dynamic Scaling
- Error Handling
- Write test codes
